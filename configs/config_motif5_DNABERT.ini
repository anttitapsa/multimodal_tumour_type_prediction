[MODEL]
#vocab_size =  #Needed for mutation embedding in original Muat 
block_size = 5000
num_class = 24
architecture = MuAtMotif
vocab_size = 0
position_size = 2915 
ges_size = 15
embed_dim = 1536
motif_len = 5
context = False
context_length = 0

[TRAINER]
max_epochs = 150
batch_size = 1
learning_rate = 6e-4
betas = (0.9, 0.95)
#grad_norm_clip = 1.0
momentum = 0.9
weight_decay = 0.001 
#only applied on matmul weights
# learning rate decay params: linear warmup followed by cosine decay to 10% of original
lr_decay = False

# checkpoint settings
ckpt_path = /scratch/project_2001668/anthuttu/multimodal/models/MuAt_motif5
#/mnt/ahuttun/multimodal/models/MuAtMotif_motiflen3
#string_logs = None
num_workers = 2
 # for DataLoader
ckpt_name = MuAt_motif5
fold =1
muat_orig = False

[DATALOADER]
data_dir = /scratch/project_2001668/anthuttu/multimodal/data/temp/motif5
#/mnt/ahuttun/multimodal/data/temp/motif3
mutation_ratio = 0.4-0.3-0.3-0-0
tumour_info_file_name = classinfo_pcawg_.csv
train_split =pcawg_train_.csv
val_split = pcawg_val_.csv
epipos = False